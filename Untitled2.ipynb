{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import read_csv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "import graphviz \n",
        "from sklearn import model_selection\n",
        "from sklearn.preprocessing import Imputer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold, learning_curve, StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import confusion_matrix, make_scorer, accuracy_score \n",
        "from sklearn import tree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.neural_network import MLPClassifier as MLPC\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "uvwH3BYS5O0l",
        "outputId": "7525dae0-9143-4c3a-ac2c-98e2980f6e82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-31aece8a2bab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_curve\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_scorer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Imputer' from 'sklearn.preprocessing' (/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
        "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
        "    \"\"\"\n",
        "    Plots a learning curve. http://scikit-learn.org/stable/modules/learning_curve.html\n",
        "    \"\"\"\n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "    plt.grid()\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
        "                     color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
        "             label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
        "             label=\"Cross-validation score\")\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "def compareABunchOfDifferentModelsAccuracy(a, b, c, d):\n",
        "    \"\"\"\n",
        "    compare performance of classifiers on X_train, X_test, Y_train, Y_test\n",
        "    http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score\n",
        "    http://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score\n",
        "    \"\"\"    \n",
        "    print('\\nCompare Multiple Classifiers: \\n')\n",
        "    print('K-Fold Cross-Validation Accuracy: \\n')\n",
        "    names = []\n",
        "    models = []\n",
        "    resultsAccuracy = []\n",
        "    models.append(('LR', LogisticRegression()))\n",
        "    models.append(('RF', RandomForestClassifier()))\n",
        "    models.append(('KNN', KNeighborsClassifier()))\n",
        "    models.append(('SVM', SVC()))\n",
        "    models.append(('LSVM', LinearSVC()))\n",
        "    models.append(('GNB', GaussianNB()))\n",
        "    models.append(('DTC', DecisionTreeClassifier()))\n",
        "    models.append(('GBC', GradientBoostingClassifier()))\n",
        "    for name, model in models:\n",
        "        model.fit(a, b)\n",
        "        kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
        "        accuracy_results = model_selection.cross_val_score(model, a,b, cv=kfold, scoring='accuracy')\n",
        "        resultsAccuracy.append(accuracy_results)\n",
        "        names.append(name)\n",
        "        accuracyMessage = \"%s: %f (%f)\" % (name, accuracy_results.mean(), accuracy_results.std())\n",
        "        print(accuracyMessage) \n",
        "    # Boxplot\n",
        "    fig = plt.figure()\n",
        "    fig.suptitle('Algorithm Comparison: Accuracy')\n",
        "    ax = fig.add_subplot(111)\n",
        "    plt.boxplot(resultsAccuracy)\n",
        "    ax.set_xticklabels(names)\n",
        "    ax.set_ylabel('Cross-Validation: Accuracy Score')\n",
        "    plt.show()    \n",
        "      \n",
        "def defineModels():\n",
        "    print('\\nLR = LogisticRegression')\n",
        "    print('RF = RandomForestClassifier')\n",
        "    print('KNN = KNeighborsClassifier')\n",
        "    print('SVM = Support Vector Machine SVC')\n",
        "    print('LSVM = LinearSVC')\n",
        "    print('GNB = GaussianNB')\n",
        "    print('DTC = DecisionTreeClassifier')\n",
        "    print('GBC = GradientBoostingClassifier \\n\\n')\n",
        "\n",
        "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
        "         \"Decision Tree\", \"Random Forest\", \"MLPClassifier\", \"AdaBoost\",\n",
        "         \"Naive Bayes\", \"QDA\"]    \n",
        "\n",
        "classifiers = [\n",
        "    KNeighborsClassifier(),\n",
        "    SVC(kernel=\"linear\"),\n",
        "    SVC(kernel=\"rbf\"),\n",
        "    GaussianProcessClassifier(),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    MLPClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GaussianNB(),\n",
        "    QuadraticDiscriminantAnalysis()\n",
        "]\n",
        "\n",
        "dict_characters = {0: 'Healthy', 1: 'Diabetes'}"
      ],
      "metadata": {
        "id": "UrkP23_65aJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " plotHistogram(values,label,feature,title):\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    plotOne = sns.FacetGrid(values, hue=label,aspect=2)\n",
        "    plotOne.map(sns.distplot,feature,kde=False)\n",
        "    plotOne.set(xlim=(0, values[feature].max()))\n",
        "    plotOne.add_legend()\n",
        "    plotOne.set_axis_labels(feature, 'Proportion')\n",
        "    plotOne.fig.suptitle(title)\n",
        "    plt.show()\n",
        "plotHistogram(dataset,\"Outcome\",'Insulin','Insulin vs Diagnosis (Blue = Healthy; Orange = Diabetes)')\n",
        "plotHistogram(dataset,\"Outcome\",'SkinThickness','SkinThickness vs Diagnosis (Blue = Healthy; Orange = Diabetes)')"
      ],
      "metadata": {
        "id": "0ZMNi38k44Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "aGW6cqWE4ufo",
        "outputId": "22e0ae48-90ff-4a1f-f19c-982e13b7801b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d0e9bc6df812>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../input/diabetes.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'read_csv' is not defined"
          ]
        }
      ],
      "source": [
        "dataset = read_csv('../input/diabetes.csv')\n",
        "dataset.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset2 = dataset.iloc[:, :-1]\n",
        "print(\"# of Rows, # of Columns: \",dataset2.shape)\n",
        "print(\"\\nColumn Name           # of Null Values\\n\")\n",
        "print((dataset2[:] == 0).sum())"
      ],
      "metadata": {
        "id": "Rzj45Au347UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"# of Rows, # of Columns: \",dataset2.shape)\n",
        "print(\"\\nColumn Name              % Null Values\\n\")\n",
        "print(((dataset2[:] == 0).sum())/768*100)"
      ],
      "metadata": {
        "id": "19TdFdnq5dzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = sns.heatmap(dataset.corr(),cmap=\"BrBG\",annot=False)\n",
        "dataset.corr()\n"
      ],
      "metadata": {
        "id": "CFsgNP2B5lUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = read_csv('../input/diabetes.csv')\n",
        "X = data.iloc[:, :-1]\n",
        "y = data.iloc[:, -1]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "imputer = Imputer(missing_values=0,strategy='median')\n",
        "X_train2 = imputer.fit_transform(X_train)\n",
        "X_test2 = imputer.transform(X_test)\n",
        "X_train3 = pd.DataFrame(X_train2)\n",
        "plotHistogram(X_train3,None,4,'Insulin vs Diagnosis (Blue = Healthy; Orange = Diabetes)')\n",
        "plotHistogram(X_train3,None,3,'SkinThickness vs Diagnosis (Blue = Healthy; Orange = Diabetes)')"
      ],
      "metadata": {
        "id": "RQ5XVYT55qkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = {0:'Pregnancies',1:'Glucose',2:'BloodPressure',3:'SkinThickness',4:'Insulin',5:'BMI',6:'DiabetesPedigreeFunction',7:'Age'}\n",
        "print(labels)\n",
        "print(\"\\nColumn #, # of Zero Values\\n\")\n",
        "print((X_train3[:] == 0).sum())\n",
        "# data[:] = data[:].replace(0, np.NaN)\n",
        "# print(\"\\nColumn #, # of Null Values\\n\")\n",
        "# print(np.isnan(X_train3).sum())"
      ],
      "metadata": {
        "id": "8P5G-l4o5qcn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compareABunchOfDifferentModelsAccuracy(X_train2, y_train, X_test2, y_test)\n",
        "defineModels()\n",
        "# iterate over classifiers; adapted from https://www.kaggle.com/hugues/basic-ml-best-of-10-classifiers\n",
        "results = {}\n",
        "for name, clf in zip(names, classifiers):\n",
        "    scores = cross_val_score(clf, X_train2, y_train, cv=5)\n",
        "    results[name] = scores\n",
        "for name, scores in results.items():\n",
        "    print(\"%20s | Accuracy: %0.2f%% (+/- %0.2f%%)\" % (name, 100*scores.mean(), 100*scores.std() * 2))"
      ],
      "metadata": {
        "id": "GZU43AKy5yvk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}